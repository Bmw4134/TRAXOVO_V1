modules = ["python-3.11", "postgresql-16", "nodejs-20", "python3"]

[nix]
channel = "stable-24_05"
packages = ["gitFull", "glibcLocales", "openssl", "pkg-config", "postgresql", "zlib"]

[deployment]
deploymentTarget = "cloudrun"
run = ["sh", "-c", "python main.py"]

[workflows]
runButton = "Start TRAXOVO"

[[workflows.workflow]]
name = "Project"
mode = "parallel"
author = "agent"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "Start application"

[[workflows.workflow]]
name = "Start application"
author = "agent"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "gunicorn --bind 0.0.0.0:5000 --reuse-port --reload main:app"
waitForPort = 5000

[[workflows.workflow]]
name = "Full Audit Deploy"
mode = "sequential"
author = 42738758

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "./replit_deploy_sync.sh"

[[workflows.workflow]]
name = "Start TRAXOVO"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python main.py"

[[workflows.workflow]]
name = "Start TRAXOVO Fast"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python app.py"

[[workflows.workflow]]
name = "Process Data Files"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python -c \""

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "import json"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "import os"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "from datetime import datetime"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = ""

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "# Fast background data processing"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "def process_gauge_data():"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "    if os.path.exists('GAUGE API PULL 1045AM_05.15.2025.json'):"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "        try:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            with open('GAUGE API PULL 1045AM_05.15.2025.json', 'r') as f:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                data = json.load(f)"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            count = len(data) if isinstance(data, list) else len(data.get('assets', []))"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            "

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            os.makedirs('data_cache', exist_ok=True)"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            with open('data_cache/asset_count.json', 'w') as f:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                json.dump({"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                    'count': count,"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                    'timestamp': datetime.now().isoformat(),"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                    'source': 'gauge_api'"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                }, f)"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            print(f'Cached {count} assets from Gauge API')"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "        except Exception as e:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            print(f'Error processing Gauge data: {e}')"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = ""

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "process_gauge_data()"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "\""

[[workflows.workflow]]
name = "Run TRAXOVO"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "gunicorn --bind 0.0.0.0:5000 --reuse-port --reload main:app"

[[workflows.workflow]]
name = "Start TRAXOVO Clean"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python app.py"

[[workflows.workflow]]
name = "Start TRAXOVO Fixed"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python app.py"

[[workflows.workflow]]
name = "Run Clean App"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python main.py"

[[workflows.workflow]]
name = "Production Server"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "gunicorn --bind 0.0.0.0:5000 --reuse-port --reload main:app"

[[workflows.workflow]]
name = "Process Data Cache"
author = 42738758
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python -c \""

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "import json"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "import os"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "from datetime import datetime"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = ""

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "def process_gauge_data():"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "    if os.path.exists('GAUGE API PULL 1045AM_05.15.2025.json'):"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "        try:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            with open('GAUGE API PULL 1045AM_05.15.2025.json', 'r') as f:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                data = json.load(f)"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            count = len(data) if isinstance(data, list) else len(data.get('assets', []))"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            "

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            os.makedirs('data_cache', exist_ok=True)"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            with open('data_cache/asset_count.json', 'w') as f:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                json.dump({"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                    'count': count,"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                    'timestamp': datetime.now().isoformat(),"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                    'source': 'gauge_api'"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "                }, f)"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            print(f'Cached {count} assets from Gauge API')"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "        except Exception as e:"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "            print(f'Error processing Gauge data: {e}')"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = ""

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "process_gauge_data()"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "\""

[[ports]]
localPort = 5000
externalPort = 80

[[ports]]
localPort = 8080
externalPort = 8080

[objectStorage]
defaultBucketID = "replit-objstore-d19509e4-169b-43c7-8bd0-1c38d79cbf89"

[env]
REPLIT_DISABLE_PACKAGE_LAYER = "1"
